# Batch data processing using AWS services

## Introduction
In this project, we will develop a batch data processing pipeline using AWS services such as S3, Glue, Redshift, and Athena, configuring
IAM roles to securely ingest large datasets into S3, transform them with Glue, load into Redshift for analytics, and
query with Athena

## Architecture:

<img width="819" height="417" alt="image" src="https://github.com/user-attachments/assets/6d87ff0f-c00e-4751-91f6-347ed1fba6be" />

## Technology Used
- Programming Language - Python
- Amazon Web Service (AWS)
1. S3 (Simple Storage Service)
2. Athena
3. Glue Crawler
4. Glue Catalog
5. Glue ETL
6. Redshift

## Dataset Used
Here is the dataset used - 
